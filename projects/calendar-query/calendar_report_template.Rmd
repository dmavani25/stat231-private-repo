---
title: "Calendar Query Individual Project"
subtitle: "STAT 231: Calendar Query"
author: "Dhyey Mavani, Class of 2025"
date: "Last updated \\today"
output: pdf_document
---

```{r setup, include = FALSE}
# SETUP CODE CHUNK:
# load packages
library(tidyverse)
library(lubridate)
library(ical)

# set code chunk defaults
knitr::opts_chunk$set(tidy = F, # display code as typed
                      size = "small", # slightly smaller code font
                      message = FALSE,
                      warning = FALSE,
                      comment = "\t") 

# set black & white default plot theme 
theme_set(theme_classic())

# improve digit and NA display 
options(digits = 6, scipen = 1, knitr.kable.NA = '')
```

<!--
Please remove my comments from the code chunks and customize the code chunks on your own, including chunk labels and options and code documentation.

You can leave my markdown comments for guidance in writing your report.

Please rename the headings. 
You may add subheadings as desired to break up the report. 
-->

# How do I spend most precious and game-changing resource of the world: TIME?
PROVIDED CODE CHUNK:
<!--
The code below is provided as a starting point for importing an `ics` file into R as a dataframe, doing some initial wrangling, and adding up the time spent on each activity. You are not required to use this code, so delete or modify it as you see fit. 

If you are using the code, be sure to update the capitalized parts with the relevant path to where your `ics` file is located, and set `eval = TRUE`.

As a reminder here's the link for exporting a Google calendar to ics (if on a Mac, you can hold cmd + click to open the page):
https://support.google.com/calendar/answer/37111?hl=en&ref_topic=10509946
-->
```{r, eval = TRUE}
# Data import and preliminary wrangling
calendar_data <- "FinalDhyeyCal.ics" %>% 
  # Use ical package to import into R
  ical_parse_df() %>% 
  # Convert to "tibble" data frame format
  as_tibble() %>% 
  mutate(
    # Use lubridate package to wrangle dates and times
    start_datetime = with_tz(start, tzone = "America/New_York"),
    end_datetime = with_tz(end, tzone = "America/New_York"),
    duration_min = difftime(end_datetime, start_datetime, units = "mins"),
    date = floor_date(start_datetime, unit = "day"),
    # Convert calendar entry to all lowercase and rename
    activity = tolower(summary))

# Compute total duration of time for each day & activity
#Creating new data set named activities
#sums up the time of each activity in entire day
activities <- calendar_data %>% 
  group_by(date, activity) %>%
  summarize(duration_min = sum(as.numeric(duration_min)))
```

\newpage
## Describe your question(s) here.  Briefly describe your data collection process, including how you defined variables of interest.


I imported my 14-day calendar data from 09-12-2021 to 09-25-2021 with Google calendar in `ical` format. I entered all events in Google calendars lying in the categories mentioned below as time progressed.

In my calendar query project:

1. `activity` represents career_related_work, sleep, meditation and procrastination as the name of activities.

2. `duration_min` represents the time duration in minutes. 

3. `actual_duration_min` represents total time spent doing that activity over the course of 14-days of data collection.

4. `intended_duration_min` represents the intended total time spent doing that activity over the course of 14-days.

5. `Total_well_being` sums up the voluntary self-care in terms of meditation and sports for better analysis of below posed questions.

### Question 1 
Document intended time doing things **(career_related_work, sleep, sports, meditation, procrastination)** versus actual time doing those things, and compare results.

### Question 2 
Document time spent in **(career_related_work) vs (Total_well_being = sports + meditation) vs sleep**

### Question 3
Document time spent in **procrastination vs (Total_well_being = sports + meditation)**


\newpage
## Describe what information is conveyed through data visualization #1 (that you'll create below) here.

**1. (bar graph, activity type on x-axis, time (both actual and intended) on y-axis, different colors for actual and intended)**

This data visualization is in form of grouped bar graph with time on y-axis and activity names on x-axis. We have two types of times: `actual_duration_min` and `intended_duration_min` representing the actual time and intended time respectively. I used a color scheme to distinguish actual and intended time duration as mentioned in the legend of visualization. I have stacked the bars relating different types of times of same activity so that we can compare between the actual and intended times without any difficulty.

```{r}
# Code for data wrangling to create an appropriate data set for visualization #1

# Creating a new data set to group the times just by activity
# Summarizing the total time consumed per activity over the data period.
time_activities <- activities %>%
  group_by(activity) %>%
  summarise("actual_duration_min" = sum(duration_min))

# Hardcoding a new data frame which stores the intended times for each activity
intended_time_activities <- data.frame(
  activity = c("career_related_work", 
               "meditation", 
               "procrastination", 
               "sleep", 
               "sports"),
  intended_duration_min = c(8300, 2160, 0, 4900, 1800))

# Joining both of the above tables by activity
# so as to have actual and intended times in same table
activities_full <- time_activities %>%
  inner_join(intended_time_activities, by = "activity")

# Dividing each activity's time field into two parts: 
# actual and intended, so as to make the visualization
# Used pivot_longer to accomplish this task.
# Used "type" to store "actual" and "intended" types of times
# Used "time" to store values
activities_full_longer <- activities_full %>%
  pivot_longer(cols = actual_duration_min:intended_duration_min,
               names_to = "type",
               values_to = "time"
  )
# Data wrangling for visualization 1 ended. 
```

```{r plot-daily-activity-data, eval = TRUE}
# Code for creating data visualization #1

# Using `ggplot` to layout the data set and specifications
# Used `position = "dodge"`to join the actual & intended bars under activity
# Used labs to add labels to different components of the generated graph
  ggplot(data = activities_full_longer,
         mapping = aes(x = activity,
                       y = time,
                       color = type,
                       fill = type)) +
  geom_col(position = "dodge")+
    labs(title = "Actual/intended time vs activity bar graph",
         subtitle = "in 2 week period",
         y = "Time",
         x = "Activity")
```
\newpage

## Describe what information is conveyed through data visualization #2 (that you'll create below) here.

**2. (Bar chart, Y & color indicating actual time in hours, X indicating modified overarching activities)**

This data visualization is in the form of bar chart with newly formed activities on x-axis and actual time in hours on y-axis. I have combined the activities sports and meditation into one overarching theme: `Total_well_being`. This facilitates a big-picture comparison in order to answer the questions posed by me as part of the calendar query assignment. In this graph we plot the actual times doing each activity in hours. Moreover, I am using the shades of blue color as a visual cue to quantify hours spent. This is intentionally implemented so that any average user can have better comparison between the far placed bars which can be deceiving by eye for some at first sight. 

```{r}
# Code for data wrangling to create an appropriate data set for visualization #2

# Using `fct_collapse` I made a new data set which has a row named 
# `Total_well_being` which I define as `sports + meditation` 
time_activities_new <- time_activities %>% 
  mutate("new_activities" = fct_collapse(
    activity, "Total_well_being" = c("sports", "meditation"))
        )

# Again summarizing total time per activity and dropping possible NAs.
new_activities_dataset <- time_activities_new %>% group_by(new_activities) %>%
  summarize("time" = sum(actual_duration_min)) %>%
  drop_na()

# redefining time in hours for better relatability
hourly_new_activities_dataset <- new_activities_dataset %>%
  mutate(time_in_hours = time/60)
```

```{r}
# Code for creating data visualization #2

# Using `ggplot` to layout the data set and specifications
# Used labs to add labels to different components of graph generated
ggplot(data = hourly_new_activities_dataset,
         mapping = aes(x = new_activities,
                       y = time_in_hours,
                       color = time_in_hours,
                       fill = time_in_hours)) +
  geom_col()+
    labs(title = "Actual time doing each activity v/s 
         broadly classified activities bar graph",
         subtitle = "in 2 week period",
         y = "Time (in hours)",
         x = "Broadly Classified Activities")
```

\newpage
## Describe what information is conveyed through the table (that you'll create below) here.


<!--
For nicer tables, check out:

* the kable function in the knitr package + the kableExtra package  
  https://bookdown.org/yihui/rmarkdown-cookbook/kable.html 
  https://bookdown.org/yihui/rmarkdown-cookbook/kableextra.html

or 

* the xtable package
  https://cran.r-project.org/web/packages/xtable/vignettes/xtableGallery.pdf
-->

The rows would be time spent doing that activity day-wise and the average time row additionally.

The columns will indicate different activities so that I can fill up the respective day-wise times on cells


```{r, results = 'asis'}
# Code for table

# Modifying activities data set by removing all NAs
# Pivoting wider to move activity to column names and duration_min to cells
initial_table <- activities %>%
  drop_na() %>%
  pivot_wider(id_cols = NULL,
               names_from = activity,
               values_from = duration_min)

# Changing the column of dates to row names
intermediate_table <- column_to_rownames(initial_table, "date")

# Creating a new data table with a new row containing activity-wise mean
mean_row <- summarize_all(intermediate_table, mean)

# Renaming the row
rownames(mean_row) <- "Average Time per activity"

# Binding them together to create a final table
# Using kable to stylize the final table
final_summarized_table <- rbind(make.row.names = T, 
                                intermediate_table, 
                                mean_row) %>%
  kableExtra::kable()

# Printing final table
final_summarized_table
```

\newpage
## To conclude, briefly summarize what you found in response to the questions posed here.

### Question 1: Document intended time doing things **(career_related_work, sleeping, sports, meditation, procrastination)** versus actual time doing those things, and compare results.

From the data visualization #1 we can see that for each of the activities there are two bars placed near each other in a color coded fashion to represent the actual and intended times for each activity in terms of height of the bars measured along the y-axis. We can infer from the visualization #1 that I am doing a decent job of fulfilling my expectations in terms of `career_related_work`, `sports`, `sleep` and `meditation`. However, I am doing 330 mins of `procrastination` over the period of 2-weeks, which is way too high according to my intended value of 0 mins per period of data collection of 14 days. Even if I devote that time to `sleep` then also I will get 20+ mins of extra `sleep` everyday, which will in turn make my `sleep` to 6 hours each day. Moreover, we can see that the amount of time I spend doing `meditation` is comparable to that of `sports`, which is surprising to me because when I am doing `meditation` it seems that time passes too fast.  

### Question 2: Document time spent in **(career_related_work) vs (Total_well_being = sports + meditation) vs sleep**

From the data visualization #2 we can see the actual time spent for each of the 3 big-picture terms I used namely `career_related_work`, `sleep`, and `Total_well_being`. Just for clarification, here by `Total_well_being` I mean total time spent in `sports` and `meditation`. We can notice that my bar for `Total_well_being` is comparable to that of `sleep`, but I have spent more time in the involuntary well being (sleep) than voluntary well being (meditation + sports), which is again expected. But, the interesting thing is there is a small chunk of time I WASTE in `procrastination`. If I devote that time to either meditation or sports or any other type of well_being which I can count under `Total_well_being`, then I would achieve a more proper balance between the voluntary and involuntary sides of well being. Moreover, I also noticed that as the semester progresses, I would need to increase my work week from near about 80 hours to 100 or 120 hours so as to accommodate aspects of career other than the regular academics. After the analysis of the plot, I can tell that I can juggle between `meditation`, `sleep` and `sports` to accommodate some more time for `career_related_work` so as to achieve a perfect work life balance where I can maintain both mental and physical peace. 

### Question 3: Document time spent in **procrastination vs (Total_well_being = sports + meditation)**

From data visualization #2 we can tell that I am doing a decent job in turning towards the side of voluntary `Total_well_being` without getting distracted to do `procrastination`. But, honestly I still think that I can further reduce the time I spend procrastinating in order to gain more mental and/or physical strength via `sports` and/or `meditation`. I don't think that `procrastination` is taking a major amount of time out of my schedule when in comes to the `career_related_work`, but I strongly believe that it is more productive to improve on actual skills and strengths which will be handy in life ahead.   

\newpage
# REFLECTION ON THE CALENDAR QUERY PROJECT <!-- e.g., Reflection -->

<!--
Write your one-page reflection here in paragraph form.  In particular, address:

* What difficulties in the data collection and analysis process did you encounter?  Identify two of your main hurdles in gathering accurate data.

* What implications does that have for future data collection and/or analysis projects? 

* How much data do you think you'd need to collect in order to answer your question(s) of interest? Would it be hard to collect that data? Why or why not?

* As someone who provides data, what expectations do you have when you give your data (e.g. to Facebook, Google, MapMyRun, etc.)?  

* As someone who analyzes others' data, what ethical responsibilities do you have?
-->

In the data collection process, sometimes I was not able to add the exact time intervals in which I performed a given activity. Moreover, I found the need to enter every specifications in the exact name of variables every time intimidating and really vague especially when I was doing 2 or more of the listed activities at the same time. In data analysis, I faced problems in wrangling and rechecking the calendar for spelling errors in activities to avoid unwanted splitting of variable data. Also, as I am a pretty consistent person as you can tell, I just added some in class hours in repetitions on the basis of daily and weekly on selected days, which didn't show up when I imported the data, so I had to manually enter everything again.

For future projects, I think I should try to enter each time slot individually as I complete the activity, so as to avoid the last time wrangling hassles. Moreover, I would highly consider reflecting upon my percentage involvement in different activities when I am doing them simultaneously and divide the time accordingly so as to minimize the sources of both random and human errors.

As far as the amount of should be data collected for my calendar query as a college student in the semester system, I think my life changes significantly as the semester progresses. So, I would rather prefer to collect data over an entire semester in order to get a better sense of my time allocations and priorities while including different situations which I encounter like tournaments and midterms. I believe that it would be difficult to be consistent and accurate at the same time while manually entering the data for such a long sample time without help of a second person in managing the accuracy of data by eliminating the bias.

In terms of Data Ethics, as a client who provides data to the companies namely Facebook, Google and MapMyRun, I expect that my data is in a safe space where no one other than me can access, edit or delete it. This comes down to data privacy. I expect these companies to store my data in a very confidential manner such as an encryption, which is random and accessible only to the person to whom the encrypted data belongs. The companies which make encryption, store data and provide functionality to render data should not be able to either access or modify the data without the consent of the user who provided the data.

Apart from my expectations from these companies, as someone who analyses the data generated by others, I have a ethical responsibility to keep all the aspects of data confidential. Also, I have the responsibility to not alter the original data while performing my analysis because I do not have the copyright or legal ownership of that data without the written legal consent of the person to whom the data belongs. 

